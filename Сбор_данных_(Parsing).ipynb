{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XslJSFkAe5-5",
        "N1UzGf1CtVfa",
        "XFUPJo-qsusT",
        "2kKiYGTFfSpV",
        "uKGJfcM39R62",
        "cJL8g8Cy96Rd",
        "xGVZmQlN9k8N"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ВЫПОЛНИЛ ГОРОХОВ Д.Е.**"
      ],
      "metadata": {
        "id": "-9VdI7wQ-0Rr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Сбор данных средствами VK API, библиотек Selenium, BeautifulSoup, фреймворка Scrapy. "
      ],
      "metadata": {
        "id": "oftpQvqjdgbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Библиотека VK API"
      ],
      "metadata": {
        "id": "XslJSFkAe5-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код, который получает список названия школ города Кемерово с помощью библиотеки vk_api и записывает результаты в файл JSON."
      ],
      "metadata": {
        "id": "Fv1R9qMftlt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import vk_api\n",
        "\n",
        "#database.getCities\n",
        "#database.getSchools\n",
        "# id Кемерово - 64\n",
        "#набор и проверка работоспособности программного кода осуществлены в MS Visual Studio Community 2019.\n",
        "\n",
        "ACCESS_TOKEN = \"vk1.a.p...\"\n",
        "vk_session = vk_api.VkApi(token=ACCESS_TOKEN)\n",
        "vk = vk_session.get_api()\n",
        "_city_id = vk.database.getCities(q=\"Кемерово\")['items'][0]['id']\n",
        "result_list = vk.database.getSchools(city_id=_city_id)\n",
        "with open(\"school.json\", \"w\") as f:    \n",
        "    result = {\"Kemerovo Schools\": result_list}\n",
        "    json.dump(result, f, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "rufJxiJufcPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Запись данных в CSV формат"
      ],
      "metadata": {
        "id": "N1UzGf1CtVfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью методов API «ВКонтакте» получаем 1000 подписчиков группы «Лентач», отсортирванных по дате регистрации.\n",
        "\n",
        "Будут собраны следующие данные в CSV файл: пол, название город, семейное положение (ФИО партнера не указывается)."
      ],
      "metadata": {
        "id": "Rg-gNSTzfA7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import vk_api\n",
        "import csv\n",
        "\n",
        "#Использование методов\n",
        "#groups.search\n",
        "#users.search\n",
        "#29534144 id Лентач\n",
        "#набор и проверка работоспособности программного кода осуществлены в MS Visual Studio Community 2019\n",
        "\n",
        "ACCESS_TOKEN = \"vk1.a....\"\n",
        "vk_session = vk_api.VkApi(token=ACCESS_TOKEN)\n",
        "vk = vk_session.get_api()\n",
        "\n",
        "#groups.search\n",
        "_group_id = vk.groups.search(q=\"Лентач\")['items'][0]['id']\n",
        "\n",
        "#users.search\n",
        "result = vk.users.search(sort=1, count=1000, fields=[\"sex\", \"city\", \"relation\" ], group_id = _group_id)\n",
        "result_list = []\n",
        "for item in result['items']:    \n",
        "    result_list.append({\n",
        "        'sex': item['sex'] if item.get('sex') else \"н/д\",\n",
        "        'city': item['city']['title'] if item.get('city') else \"city - н/д\",\n",
        "        'relation': item['relation'] if item.get('relation') else \"relation - н/д\"\n",
        "        })\n",
        "\n",
        "# Запись данных в CSV файл\n",
        "with open('subscribersLentach.csv', 'w', encoding='utf-8', newline='\\n') as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=list(result_list[0].keys()), quoting=csv.QUOTE_NONNUMERIC)\n",
        "    writer.writeheader()\n",
        "    for row in result_list:\n",
        "        writer.writerow(row)\n",
        "\n",
        "with open('subscribersLentach.csv', 'r', encoding='utf-8', newline='\\n') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "eSslPXrGfDRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Скрещиваем Selenium и BeautifulSoup"
      ],
      "metadata": {
        "id": "XFUPJo-qsusT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сбор информации с сайта nbcomputers.ru (https://www.nbcomputers.ru/catalog/noutbuki/) о ноутбуках данного интернет-магазина.\n",
        "<br>\n",
        "Собираются данные:\n",
        "* Название ноутбука\n",
        "* Цена ноутбука\n",
        "* Код товара\n",
        "\n",
        "Результат записывается в CSV файл.\n",
        "<br>\n",
        "*(P.S.: между прокликами сделаны различные временные промежутки для подгрузки страниц сайта)*"
      ],
      "metadata": {
        "id": "9O8NOJs51u8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import csv\n",
        "\n",
        "#набор и проверка работоспособности программного кода осуществлены в MS Visual Studio Community 2019\n",
        "\n",
        "def get_html():\n",
        "    service = Service(executable_path=ChromeDriverManager().install())\n",
        "    driver = webdriver.Chrome(service=service)\n",
        "    \n",
        "    try:\n",
        "        driver.get(\"https://www.nbcomputers.ru/catalog/noutbuki/\")    \n",
        "        driver.implicitly_wait(5)        \n",
        "        \n",
        "        actions = ActionChains(driver)    \n",
        "        actions.move_to_element(driver.find_element(By.CLASS_NAME, \"sc-47746e2f-0\"))\n",
        "        actions.perform()\n",
        "            \n",
        "        while True:\n",
        "            wait_number = random.randint(3, 10)\n",
        "            wait = WebDriverWait(driver, timeout=wait_number)    \n",
        "            wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"sc-47746e2f-0\"))).click()        \n",
        "\n",
        "    except Exception as ex:\n",
        "        print(f'Error: {ex}')    \n",
        "\n",
        "    html_kod = driver.page_source\n",
        "    driver.quit()\n",
        "    with open(\"task3_html.txt\", 'w', encoding='utf-8') as f:\n",
        "            f.write(html_kod)\n",
        "\n",
        "def get_csv():\n",
        "    with open('task3_html.txt', 'r', encoding='utf-8', newline='\\n') as f:\n",
        "        html = f.read()\n",
        "    soap = BeautifulSoup(html, 'lxml')\n",
        "    cards_list = soap.select_one('div.fLwRJw')\n",
        "    cards = cards_list.select('div.hiQXWK')\n",
        "    noutbooks_info = []\n",
        "    for card in cards:    \n",
        "        name = card.select_one('div.buPdmH h2').text\n",
        "        code = card.select_one('div.eLONJb p').text.split(\" \")[1]\n",
        "        price = card.select_one('div.KDZKI').text.split('₽')[0]\n",
        "        noutbooks_info.append({\n",
        "        'Name': name,\n",
        "        'Price': price,\n",
        "        'Code': code\n",
        "        })\n",
        "    with open('task3_noutbooksInfo.csv', 'w', encoding='utf-8', newline='\\n') as f:\n",
        "        writer = csv.DictWriter(f, noutbooks_info[0].keys())\n",
        "        writer.writeheader()\n",
        "        for row in noutbooks_info:\n",
        "            writer.writerow(row)"
      ],
      "metadata": {
        "id": "ORwgF2mYffFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Фреймворк Scrapy"
      ],
      "metadata": {
        "id": "2kKiYGTFfSpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сбор информации о заквасках с сайта pro-syr.ru (https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
        "\n",
        "Осуществляется сбор следующих данныех:\n",
        "* Название продукта\n",
        "* Цена\n",
        "* Есть ли продукт в наличии\n",
        "\n",
        "Результат записывается в CSV файл"
      ],
      "metadata": {
        "id": "A6UOPxtk563f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "import time\n",
        "\n",
        "#набор и проверка работоспособности программного кода осуществлены в MS Visual Studio Community 2019\n",
        "#строка запуска файла в cmd: scrapy runspider \"PythonApp_Ex4_Scrapy.py\" -o \"zakvaski_Ex4.csv\"\n",
        "\n",
        "class ZakvaskiSpider(scrapy.Spider):\n",
        "    name = \"ZakvaskiSpider\"\n",
        "    start_urls = [\"https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/\"]\n",
        "\n",
        "    def parse(self, response):\n",
        "        links = response.css(\"div.nameproduct a::attr(href)\")\n",
        "        for link in links:\n",
        "            time.sleep(3)\n",
        "            yield response.follow(link, self.parse_zakvaski)\n",
        "\n",
        "        link = response.css(\"ul.pagination a::attr(href)\")[-1].get()\n",
        "        yield response.follow(link, self.parse)\n",
        "\n",
        "    def parse_zakvaski(self, response):\n",
        "        yield {\n",
        "            \"name\": response.css(\"div.row h1::text\").get(),\n",
        "            \"price\": response.css(\"li.price h2 span.autocalc-product-price::text\").get(),\n",
        "            \"availability\": response.css(\"div.product-description b::text\").get(),\n",
        "        }"
      ],
      "metadata": {
        "id": "0zUq-Xwlfgjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Дополнительно**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uKGJfcM39R62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Сбор данныех с помощью Requests"
      ],
      "metadata": {
        "id": "cJL8g8Cy96Rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью методов API ВКонтакте получаем список высших учебных заведений и названия их факультетов в городе Томск.\n",
        "Результат записывается в файл JSON в следующем формате:"
      ],
      "metadata": {
        "id": "MgvkdXgsex5B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiF3TeikBTrD"
      },
      "outputs": [],
      "source": [
        "\"result\": {\n",
        "  \"cities\": [\n",
        "    {   \n",
        "        \"id\": <ID города>,\n",
        "        \"name\": <Название города>,\n",
        "        \"universites\": [\n",
        "            {\n",
        "              \"id\": <ID ВУЗа>, \n",
        "              \"name\": <Название ВУЗа>\n",
        "              \"faculties\": [<Название факультета>, …]\n",
        "            },\n",
        "            ...\n",
        "        ]\n",
        "    },\n",
        "    ...\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import vk_api\n",
        "\n",
        "#набор и проверка работоспособности программного кода осуществлены в MS Visual Studio Community 2019\n",
        "\n",
        "ACCESS_TOKEN = \"vk1.a....\"\n",
        "vk_session = vk_api.VkApi(token=ACCESS_TOKEN)\n",
        "vk = vk_session.get_api()\n",
        "\n",
        "faculties = []\n",
        "NAME_CITY = 'Томск'\n",
        "city_id = vk.database.getCities(q=NAME_CITY)['items'][0]['id']\n",
        "universities = vk.database.getUniversities(city_id=city_id)['items']\n",
        "university_id = [elem['id'] for elem in universities]\n",
        "nameUniversities = [elem['title'] for elem in universities]\n",
        "for id in university_id:\n",
        "    faculties.append(vk.database.getFaculties(university_id=id)['items'])\n",
        "    nameFaculties = [[f['title'] for f in fac] for fac in faculties]\n",
        "result_list = [] \n",
        "for nU, uID, nF in zip(nameUniversities, university_id, nameFaculties):    \n",
        "    result_list.append({\n",
        "                \"id\": uID,\n",
        "                \"name\": nU,\n",
        "                \"name faculties\": nF\n",
        "                })       \n",
        "d = {\"result\": {\"cities\": [{\"id\": city_id, \"name\": NAME_CITY}]}}\n",
        "d['result']['cities'][0]['universities']=result_list\n",
        "result = []\n",
        "result.append(d)\n",
        "with open(\"tomskUniversities.json\", \"w\") as f:    \n",
        "    result = {\"Tomsk Universities\": result}\n",
        "    json.dump(result, f, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "RbPFOD0999QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Библиотека BeautifulSoup"
      ],
      "metadata": {
        "id": "xGVZmQlN9k8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код, который собирает список знаменательных дат в формате «чисто месяц год» с первой страницы сайта GCTC.ru (https://www.gctc.ru/main.php?id=98.1)"
      ],
      "metadata": {
        "id": "EvfKn3WArL8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import lxml\n",
        "import csv\n",
        "\n",
        "#набор и проверка работоспособности программного кода осуществлены в MS Visual Studio Community 2019\n",
        "\n",
        "URL = \"https://www.gctc.ru/main.php?id=98.{}\"\n",
        "\n",
        "session = requests.session()\n",
        "session.headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
        "    'Accept-Language': 'ru,ru-RU;q=0.9,en-US;q=0.8,en;q=0.7'}\n",
        "\n",
        "months = {\"января\":\"январь\", \"февраля\":\"февраль\", \"марта\":\"март\",\"апреля\":\"апрель\",\"мая\":\"май\",\"июня\":\"июнь\",\"июля\":\"июль\",\"августа\":\"август\",\"сентября\":\"сентябрь\",\"октября\":\"октябрь\",\"ноября\":\"ноябрь\",\"декабря\":\"декабрь\"}\n",
        "result = []\n",
        "for page in range(1,13):\n",
        "    res = session.get(URL.format(page))\n",
        "    soap = BeautifulSoup(res.text, 'lxml')  \n",
        "    informs = soap.select_one('div.ie_infoh')\n",
        "    dates = informs.select('h1.shad')\n",
        "    years = informs.select('div.news')\n",
        "\n",
        "    for date, year in zip(dates, years):\n",
        "        day = date.text[:2]\n",
        "        mm = months[date.select_one('span.s12').text]    \n",
        "        yy = year.select_one('h2').text.split()[0]\n",
        "        even = year.text.split('\\n')[1]\n",
        "        result.append({\n",
        "            'число':day,\n",
        "            'месяц': mm,\n",
        "            'год': yy,\n",
        "            'событие': even\n",
        "            })\n",
        "\n",
        "with open('addTask2.csv', 'w', encoding=\"utf-8\", newline='\\n') as f:\n",
        "  writer = csv.DictWriter(f, result[0].keys())\n",
        "  writer.writeheader()\n",
        "  for row in result:\n",
        "    writer.writerow(row)"
      ],
      "metadata": {
        "id": "Sdn8-Ot-9eSY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}